{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import LambdaCallback\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import io\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "path = './data/names.txt'\n",
    "with io.open(path, encoding='utf-8') as f:\n",
    "    text = f.read().lower()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total chars: 71\n",
      "['\\n', ' ', '-', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'x', 'y', 'z', 'ʻ', 'а', 'б', 'в', 'г', 'д', 'е', 'ж', 'з', 'и', 'й', 'к', 'л', 'м', 'н', 'о', 'п', 'р', 'с', 'т', 'у', 'ф', 'х', 'ц', 'ч', 'ш', 'щ', 'ъ', 'ы', 'ь', 'э', 'ю', 'я', 'ё', 'і', 'ғ', 'қ', 'ң', 'ү', 'ұ', 'һ', 'ә', 'ө']\n"
     ]
    }
   ],
   "source": [
    "text = text.replace(\"'\", \"\")\n",
    "chars = sorted(list(set(text)))\n",
    "print('total chars:', len(chars))\n",
    "print(chars)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'\\n': 0, ' ': 1, '-': 2, 'a': 3, 'b': 4, 'c': 5, 'd': 6, 'e': 7, 'f': 8, 'g': 9, 'h': 10, 'i': 11, 'j': 12, 'k': 13, 'l': 14, 'm': 15, 'n': 16, 'o': 17, 'p': 18, 'q': 19, 'r': 20, 's': 21, 't': 22, 'u': 23, 'v': 24, 'x': 25, 'y': 26, 'z': 27, 'ʻ': 28, 'а': 29, 'б': 30, 'в': 31, 'г': 32, 'д': 33, 'е': 34, 'ж': 35, 'з': 36, 'и': 37, 'й': 38, 'к': 39, 'л': 40, 'м': 41, 'н': 42, 'о': 43, 'п': 44, 'р': 45, 'с': 46, 'т': 47, 'у': 48, 'ф': 49, 'х': 50, 'ц': 51, 'ч': 52, 'ш': 53, 'щ': 54, 'ъ': 55, 'ы': 56, 'ь': 57, 'э': 58, 'ю': 59, 'я': 60, 'ё': 61, 'і': 62, 'ғ': 63, 'қ': 64, 'ң': 65, 'ү': 66, 'ұ': 67, 'һ': 68, 'ә': 69, 'ө': 70}\n"
     ]
    }
   ],
   "source": [
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "print(char_indices)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{' ': 1, '\"': 2, '-': 3, ':': 4, ';': 5, 'a': 6, 'b': 7, 'c': 8, 'd': 9, 'e': 10, 'f': 11, 'g': 12, 'h': 13, 'i': 14, 'j': 15, 'k': 16, 'l': 17, 'm': 18, 'n': 19, 'o': 20, 'p': 21, 'q': 22, 'r': 23, 's': 24, 't': 25, 'u': 26, 'v': 27, 'x': 28, 'y': 29, 'z': 30, 'ʻ': 31, 'а': 32, 'б': 33, 'в': 34, 'г': 35, 'д': 36, 'е': 37, 'ж': 38, 'з': 39, 'и': 40, 'й': 41, 'к': 42, 'л': 43, 'м': 44, 'н': 45, 'о': 46, 'п': 47, 'р': 48, 'с': 49, 'т': 50, 'у': 51, 'ф': 52, 'х': 53, 'ц': 54, 'ч': 55, 'ш': 56, 'щ': 57, 'ъ': 58, 'ы': 59, 'ь': 60, 'э': 61, 'ю': 62, 'я': 63, 'ё': 64, 'і': 65, 'ғ': 66, 'қ': 67, 'ң': 68, 'ү': 69, 'ұ': 70, 'һ': 71, 'ә': 72, 'ө': 73}\n"
     ]
    }
   ],
   "source": [
    "ix_to_char={i:ch for i,ch in enumerate(chars)}\n",
    "char_to_ix={ch:i for i,ch in enumerate(chars)}\n",
    "print(char_to_ix)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of lines: 56059\n"
     ]
    }
   ],
   "source": [
    "lines = text.split('\\n')\n",
    "lines = [line for line in lines if len(line)!=0]\n",
    "print(\"number of lines:\", len(lines))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "line with longest length: 41\n",
      "line with shorter length: 7\n"
     ]
    }
   ],
   "source": [
    "maxlen = len(max(lines, key=len))\n",
    "minlen = len(min(lines, key=len))\n",
    "\n",
    "print(\"line with longest length: \"+ str(maxlen))\n",
    "print(\"line with shorter length: \"+ str(minlen))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "steps = 1\n",
    "sequences = []\n",
    "next_chars = []\n",
    "\n",
    "for line in lines:\n",
    "    # pre-padding with zeros\n",
    "    s = (maxlen - len(line))*'0' + line\n",
    "    sequences.append(s)\n",
    "    next_chars.append('\\n')\n",
    "    for it,j in enumerate(line):\n",
    "        if (it >= len(line)-1):\n",
    "            continue\n",
    "        s = (maxlen - len(line[:-1-it]))*'0' + line[:-1-it]\n",
    "        sequences.append(s)\n",
    "        next_chars.append(line[-1-it])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total sequences: 1421295\n",
      "00000000000000000000000000ерболатова акбо т\n",
      "000000000000000000000000000ерболатова акб о\n",
      "0000000000000000000000000000ерболатова ак б\n"
     ]
    }
   ],
   "source": [
    "print('total sequences:', len(sequences))\n",
    "print(sequences[66], next_chars[66])\n",
    "print(sequences[67], next_chars[67])\n",
    "print(sequences[68], next_chars[68])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8h/xg2d0hkn4xng7c08vc_2khgr0000gn/T/ipykernel_12366/4182269958.py:1: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  x = np.zeros((len(sequences), maxlen, len(chars)), dtype=np.bool)\n",
      "/var/folders/8h/xg2d0hkn4xng7c08vc_2khgr0000gn/T/ipykernel_12366/4182269958.py:2: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y = np.zeros((len(sequences), len(chars)), dtype=np.bool)\n"
     ]
    }
   ],
   "source": [
    "x = np.zeros((len(sequences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sequences), len(chars)), dtype=np.bool)\n",
    "for i, seq in enumerate(sequences):\n",
    "    for t, char in enumerate(seq):\n",
    "        if char != '0':\n",
    "            x[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "prefix = \"\"\n",
    "max_names = 10\n",
    "\n",
    "def sample(preds):\n",
    "    \"\"\" function that sample an index from a probability array \"\"\"\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = preds / np.sum(preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.random.choice(range(len(chars)), p = probas.ravel())\n",
    "\n",
    "def print_name_generated(name):\n",
    "    print(name, flush=True)\n",
    "def print_list_generated(lst):\n",
    "    print(lst, flush=True)\n",
    "\n",
    "\n",
    "def generate_new_names(*args):\n",
    "    print(\"----------Generatinig names----------\")\n",
    "\n",
    "    # Add pre-padding of zeros in the input.\n",
    "    sequence = ('{0:0>' + str(maxlen) + '}').format(prefix).lower()\n",
    "\n",
    "    # tmp variables\n",
    "    tmp_generated = prefix\n",
    "    list_outputs = list()\n",
    "\n",
    "    while len(list_outputs) < max_names:\n",
    "\n",
    "        # Vectorize the input of the model.\n",
    "        x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "        for t, char in enumerate(sequence):\n",
    "            if char != '0':\n",
    "                x_pred[0, t, char_indices[char]] = 1\n",
    "\n",
    "        # Predict the probabilities of the next char.\n",
    "        preds = model.predict(x_pred, verbose=0)[0]\n",
    "\n",
    "        # Chose one based on the distribution obtained in the output of the model.\n",
    "        next_index = sample(preds)\n",
    "        # Get the corresponding char.\n",
    "        next_char = indices_char[next_index]\n",
    "\n",
    "        # If the char is a new line character or the name start to be bigger than the longest word,\n",
    "        # try to add it to the list and reset temp variables.\n",
    "        if next_char == '\\n' or len(tmp_generated) > maxlen:\n",
    "\n",
    "            # If the name generated is not in the list, append it and print it.\n",
    "            if tmp_generated not in list_outputs:\n",
    "                list_outputs.append(tmp_generated)\n",
    "                print_name_generated(tmp_generated)\n",
    "            # Reset tmp variables\n",
    "            sequence = ('{0:0>' + str(maxlen) + '}').format(prefix).lower()\n",
    "            tmp_generated = prefix\n",
    "        else:\n",
    "\n",
    "            # Append the char to the sequence that we're generating.\n",
    "            tmp_generated += next_char\n",
    "            # Add pre-padding of zeros to the sequence generated and continue.\n",
    "            sequence = ('{0:0>' + str(maxlen) + '}').format(tmp_generated).lower()\n",
    "\n",
    "    # Show the intersection of the words generated and your dataset. .\n",
    "    print(\"Set of words already in the dataset:\")\n",
    "    print_list_generated(set(lines).intersection(list_outputs))\n",
    "\n",
    "    # Show the rate of how many repeated words you've created.\n",
    "    total_repited = len(set(lines).intersection(list_outputs))\n",
    "    total = len(list_outputs)\n",
    "    print(\"Rate of total invented words: \" + \"{:.2f}\".format((total-total_repited)/total))\n",
    "    print(\"-----------------End-----------------\")\n",
    "\n",
    "# Function invoked at the end of each epoch. Prints generated names.\n",
    "callback = LambdaCallback(on_epoch_end=generate_new_names)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cyber/anaconda3/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/rmsprop.py:140: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------Generatinig names----------\n",
      "дорманов мадин әбілханұлы\n",
      "тактемев жансалин болатжанович\n",
      "загопилжай айгерим ұлыққызы\n",
      "шодынулла нұртас бауыржанұлы\n",
      "оразгаир бекадел ныркубайулы\n",
      "эфильв марат улугович\n",
      "вазбағолова жарсын сәженярқызы\n",
      "киратовн андра александрович\n",
      "әдылжанова темірлан маматұлы\n",
      "биденова динара болатовна\n",
      "Set of words already in the dataset:\n",
      "set()\n",
      "Rate of total invented words: 1.00\n",
      "-----------------End-----------------\n",
      "11104/11104 - 458s - loss: 1.3033 - 458s/epoch - 41ms/step\n",
      "Epoch 2/2\n",
      "----------Generatinig names----------\n",
      "жұмабергенбекова ернұр қайратқызы\n",
      "шуомохар дарина данияровна\n",
      "черков витальдра евгеньевич\n",
      "эруекова айша дариянқызы\n",
      " нұрсұлтан маратұлы\n",
      "жайдар нұрай абдуғынұрланқызы\n",
      "фарсов набыс назирыс сейсентович\n",
      "гайратов назерке матжановна\n",
      "мазадин ильяс алийглы\n",
      "эроргеидина слеөмана думанқызы\n",
      "Set of words already in the dataset:\n",
      "set()\n",
      "Rate of total invented words: 1.00\n",
      "-----------------End-----------------\n",
      "11104/11104 - 458s - loss: 1.1628 - 458s/epoch - 41ms/step\n"
     ]
    }
   ],
   "source": [
    "# build and train the model\n",
    "model = Sequential()\n",
    "model.add(LSTM(64, input_shape=(maxlen, len(chars))))\n",
    "model.add(Dense(len(chars), activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(lr=0.01))\n",
    "history = model.fit(x, y, batch_size=128, epochs=2, verbose=2, callbacks=[callback])\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
